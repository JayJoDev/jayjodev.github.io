---
title: Overview of Recommendation System
author: Jay Jo
date: 2023-11-04 00:00:00 +09:00
categories: [Artificial Intelligence]
tags: [AI]
image: /assets/img/posts/Recommendation-system.png
---

## 추천시스템 

**개인화 추천 시스템**: 과거 사용자의 행동 데이터나 다른 데이터를 바탕으로 사용자에게 필요한 정보나 제품을 골라서 제시해 주는 시스템 
전통적인 비지니스에서 추천은 고객들의 취향이 비슷한 집단 (마케팅에서는 세그먼트)
집단의 크기를 아주 작게 하면 한 사람이 되고 각 사용자별로 맞춤형 추천과 서비스를 제공하는 것을 **개인화** 라고 한다.

### 주요 알고리즘

1. Content-Based Filtering (CB)

- 특징: 이 방식은 사용자가 과거에 선호했던 제품의 내용(예: 텍스트, 특징)을 분석하여 비슷한 제품을 추천합니다.
- 적용 분야: 텍스트 같은 내용 기반의 데이터에 적합합니다.

2. Collaborative Filtering (CF)

- 특징: 사용자 간의 상호 작용(예: 평점, 구매)을 기반으로 하여 추천합니다. 이는 사용자들 사이의 유사성을 찾아 그 유사성을 기반으로 추천을 합니다.
- 적용 분야: 영화, 음악, 패션 등 취향이 중요한 분야에 적합합니다.
- 단점: 새로운 사용자나 제품에 대한 데이터가 부족할 때 ("콜드 스타트" 문제) 추천 품질이 떨어질 수 있습니다.

3. Knowledge-Based Filtering (KB)

- 특징: 전문가의 지식을 활용하여 사용자의 필요나 조건에 맞는 제품을 추천합니다.
- 적용 분야: 복잡한 제품이나 서비스(예: 부동산, 금융 상품)에 적합합니다.

4. Factorization Machines (FM)

- 특징: 데이터 내의 특징들 간의 모든 상호작용을 고려하는 방식으로, 행렬 분해와 유사하지만 더 유연하고 일반화된 형태입니다. 이는 사용자와 아이템 간의 상호작용을 포함하여 다양한 유형의 데이터를 모델링할 수 있습니다.
- 적용 분야: 희소 데이터셋에서의 추천, 회귀, 분류 작업에 적합합니다.
- 차이점: CB, CF와 달리 특징 간의 복잡한 상호작용을 모델링할 수 있으며, KB, DL 방식과는 다르게 특정 도메인 지식이나 심층적인 데이터 구조를 필요로 하지 않습니다.

5. Deep Learning (DL)

- 특징: 심층 신경망을 사용하여 복잡한 패턴과 관계를 학습합니다.
- 적용 분야: 대용량의 데이터와 복잡한 사용자-제품 상호작용을 다루는 분야에 적합합니다.

6. Hybrid

- 특징: 위의 여러 기법들을 조합하여 사용합니다. 이는 각 기법의 장점을 활용하고 단점을 보완할 수 있습니다.

## 기본 추천 시스템

1. 베스트 Seller 방식: 개별 사용자의 정보가 없는 경우
-. 세분화 성별/나이/직업 등 으로 가능

### Content-Based filtering (CB)

절차
1. 각 아이템 간의 유사도 (Similarity)를 계산한다.
- 텍스트의 유사도 측정의 대표적인 방법은 tf-idf 방법이있다.
2. 추천 대상이 되는 사용자가 선호하는(좋게 평가한) 아이템을 선정한다.
3. 선정된 아이템과 가장 유사도가 높은 N개의 아이템을 찾는다.
4. N개의 아이템을 추천한다.


### Collaborative filtering (CF)
성별, 나이, 직업별 추천이 생각보다 정확한 결과를 내지 못함
이 방법은 취향(취향의 유사도)을 기준으로 나눔

CF는 사용자들의 평가를 기반으로 사용자 간 유사도를 구하는 것이 핵힘

### 유사도 측정법
1. 상관계수
2. 코사인 유사도
3. 타니모토 계수 (데이터가 이진값일 경우) / 자카드 계수

유사도계수로 이웃을 정하는 방법
1. 이웃의 크기(갯수)를 미리 정해 놓고 추천 대상 사용자와 가장 유사한 K명을 선택하는 "K Nearnest Neighbors(KNN)" 방법 
2. 크기 대신 유사도 기준 (예, 상관계수 0.8 이상)을 정해 놓고 이기준 을 충족 시키는 사용자를 이웃으로 정하는 Thresholding 방법

일반적으로 Thresholding > KNN 방법이 정확하나 정해진 기준을 사용자가 없어 추천을 못하는 경우가 많아 **KNN**이 주로 쓰임.

최적의 이웃 크기 결정도 중요한데 이웃의 크기가 지나치게 크면 개인의 취향이 반영이 안된다. 
* Machine Learning에 Over-fitting과 유사

사용자 기반 / 아이템 기반 유사도 측정이 가능

1. 사용자 기반: 데이터가 풍부할때 정확한 추천 가능 | 업데이트 주기가 많이 필요
2. 아이템기반: 사용자별 따로 계산 하지 않아도 되어 계산이 빠름 | 업데이트 주기가 많이 필요하지 않음 


## Matrix Factorization의 기본 개념:
목적: 사용자-아이템 상호 작용 행렬을 더 작은 '사용자 요인 행렬'과 '아이템 요인 행렬'로 분해합니다. 이 분해는 원래 행렬의 데이터를 가능한 잘 근사하려는 목적으로 이루어집니다.

## 작동 원리:

사용자 행렬(User Matrix)은 각 사용자를 요인(또는 특성)의 집합으로 나타냅니다.
아이템 행렬(Item Matrix)은 각 아이템을 동일한 요인의 집합으로 나타냅니다.
사용자와 아이템 행렬의 요인들이 상호 작용하여 원래의 사용자-아이템 상호 작용 행렬을 재구성합니다.
적용:

이러한 분해를 통해, 시스템은 사용자가 아직 상호 작용하지 않은 아이템에 대한 예측 선호도를 계산할 수 있습니다.
이 방법은 특히 희소 행렬에 효과적이며, 추천 시스템에서 'Cold Start' 문제를 다루는 데 도움이 됩니다.
알고리즘 예시:

### Matrix Factorization (MF)의 주요 알고리즘 및 SGD의 역할:
1. Singular Value Decomposition (SVD):

SVD는 사용자-아이템 상호 작용 행렬을 세 개의 행렬로 분해하는 방법입니다. 이 방법은 명시적 평점 데이터에 적합하며, 누락된 값이 없는 경우에 효과적입니다.
Non-negative Matrix Factorization (NMF):

NMF는 모든 요소가 음수가 아닌 두 행렬로 원래 행렬을 분해합니다. 이 방법은 데이터의 부분 집합을 해석하는 데 유용하며, 대체로 비음수 데이터에 적용됩니다.

2. Stochastic Gradient Descent (SGD):

SGD는 Matrix Factorization 모델의 최적화에 사용됩니다. 이는 각 단계에서 무작위로 선택된 하나의 데이터 포인트(또는 작은 배치)를 사용하여 모델의 매개변수를 점진적으로 조정합니다.
SGD는 대규모 및 희소 데이터 세트에서 효율적인 최적화를 제공하며, 모델의 학습 과정을 실시간으로 업데이트하는 데 유용합니다.

3. Matrix Factorization의 적용 및 중요성:
MF를 사용하여, 시스템은 사용자가 아직 상호 작용하지 않은 아이템에 대한 예측 선호도를 계산할 수 있습니다. 이는 특히 희소 행렬에서 효과적이며, 추천 시스템의 'Cold Start' 문제에 대응하는 데 도움이 됩니다.

MF는 사용자의 숨겨진 선호와 아이템의 숨겨진 특성을 발견하는 데 중요한 역할을 합니다. 이를 통해 시스템은 보다 정확하고 개인화된 추천을 제공할 수 있습니다.

이러한 알고리즘들은 각기 다른 상황과 데이터 유형에 적합하며, MF의 구현 및 최적화에 있어서 서로 보완적인 역할을 합니다. 특히, SGD는 대규모 데이터 세트를 효율적으로 처리하고, 실시간으로 모델을 조정하는 데 매우 중요한 역할을 수행합니다.

## 다른 주요 추천시스템과 Matrix Factorization의 차이
### Content-Based Filtering (CB):

이 방식은 아이템의 내용(예: 텍스트, 특성)을 분석하여 사용자에게 추천합니다.
Matrix Factorization과의 차이: CB는 아이템의 내용에 초점을 맞추지만, MF는 사용자와 아이템 간의 상호 작용을 분석합니다.

### Collaborative Filtering (CF):

CF는 사용자들의 과거 행동(예: 평가, 구매)을 기반으로 상호 작용 패턴이 유사한 사용자들에게 추천합니다.
Matrix Factorization은 CF의 한 형태로, 사용자와 아이템 사이의 상호 작용을 분석하여 추천을 생성합니다.

### Knowledge-Based Filtering (KB):

KB는 특정 분야의 전문 지식을 활용하여 사용자에게 추천합니다.
Matrix Factorization과의 차이: KB는 전문가의 지식에 기반하지만, MF는 데이터에서 숨겨진 패턴을 찾아내는 데 초점을 맞춥니다.

### Deep Learning (DL):

DL은 심층 신경망을 사용하여 추천을 생성합니다. 이는 복잡한 데이터 구조를 학습할 수 있는 능력을 가지고 있습니다.
Matrix Factorization과의 차이: DL은 복잡한 비선형 관계를 모델링할 수 있지만, 전통적인 MF는 선형 요인 모델에 기반합니다.

### Hybrid:

하이브리드 방식은 여러 추천 기술을 결합하여 사용합니다.
Matrix Factorization은 하이브리드 시스템의 일부로 사용될 수 있으며, 다른 접근 방식과 결합될 때 각기 다른 장점을 보완할 수 있습니다.
Matrix Factorization은 데이터에서 숨겨진 패턴을 찾아내고, 이를 통해 사용자와 아이템 간의 관계를 예측하는 데 중점을 두는 CF의 한 방식입니다. 다른 추천 시스템 방식과의 주요 차이는 데이터 분석과 모델링 접근 방법에 있습니다.

## Factorization Machines (FM)

Factorization Machines (FM)은 추천 시스템에서 사용되는 고급 알고리즘 중 하나로, 사용자-아이템 상호작용 및 기타 특징들 간의 상호작용을 모델링하는 데 특히 유용합니다. FM의 주요 특징과 작동 원리를 자세히 살펴보겠습니다:

### FM의 핵심 개념

1. 다차원 상호작용 모델링: 
FM은 데이터 내의 특징들 간의 모든 상호작용을 포착하는 것을 목표로 합니다. 이는 특히 희소 데이터셋에서 유용한데, 이러한 데이터셋에서는 다른 알고리즘들이 놓칠 수 있는 패턴을 발견할 수 있습니다.

2. 유연성과 일반화: 
FM은 다양한 유형의 데이터(예: 사용자 특징, 아이템 특징)에 적용될 수 있으며, 이를 통해 행렬 분해 기법보다 더 유연하고 일반화된 모델을 제공합니다.

3. 희소 데이터에서의 강점: 
FM은 특히 희소한 데이터셋에서 강력한 성능을 발휘합니다. 이는 추천 시스템에서 흔히 발생하는 콜드 스타트 문제를 해결하는 데 도움이 됩니다.

4. 작동 원리
FM은 각 특징의 잠재적인 인터랙션을 모델링하기 위해 인수 분해 기법을 사용합니다. 기본적으로, 각 특징은 잠재적인 요인 벡터로 표현되며, 이 벡터들의 상호작용을 통해 예측이 이루어집니다. 이 방식은 특징 간의 복잡한 관계를 포착할 수 있으며, 특히 사용자와 아이템 간의 상호작용을 효과적으로 모델링할 수 있습니다.

5. 주요 용도
FM은 추천 시스템뿐만 아니라, 회귀, 분류 및 랭킹 문제에도 적용될 수 있습니다. 이는 FM이 다양한 유형의 데이터와 상호작용을 처리할 수 있는 능력 덕분입니다.

6. 장점 및 단점
장점:
희소 데이터셋에서 강력한 성능
다양한 유형의 데이터와 상호작용 모델링 가능
콜드 스타트 문제에 대한 효과적인 대응
7. 단점:
상대적으로 복잡한 알고리즘으로 인한 구현의 어려움
매개변수 조정이 중요하며, 때때로 이에 대한 전문 지식이 요구될 수 있음
FM은 이러한 특징들을 바탕으로, 특히 사용자의 선호도나 아이템의 속성이 잘 정의되지 않은 경우에 유리한 방식으로 활용될 수 있습니다. 이를 통해 추천 시스템은 사용자에게 보다 정확하고 개인화된 추천을 제공할 수 있습니다.

### 정확도 측정 (RMSE) 및 성과 지표

**수식** 간단한 텍스트로 표현한 RMSE의 수식은 다음과 같다:
$$
\text{RMSE} = \sqrt{\frac{\sum{(y_i - \hat{y}_i)^2}}{n}}
$$

여기서 
$$
n 
$$ 은 관측치의 총 개수, 
$$
y_i
$$ 는 각 관측치의 실제 값, 
$$
\hat{y}_i
$$ 는 예측 값입니다. 이 수식은 실제 값과 예측 값 간의 차이를 제곱하여 평균을 낸 후, 그 제곱근을 취함으로써 계산됩니다.

# 분류 성능 지표

| 실제 / 예측 | 양성 예측 (Positive Prediction) | 음성 예측 (Negative Prediction) |
| ----------- | ----------------------------- | ----------------------------- |
| 실제 양성 (Actual Positive) | True Positives (TP) | False Negatives (FN) |
| 실제 음성 (Actual Negative) | False Positives (FP) | True Negatives (TN) |

## 계산식

- **정확도 (Accuracy)**:  
  $$ \text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}} $$

- **정밀도 (Precision)**:  
  $$ \text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}} $$

- **재현율 (Recall)**:  
  $$ \text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}} $$


### 1. 정확도 (Accuracy)
- **설명**: 전체 예측 중 올바른 예측의 비율
- **계산**: 
  $$ \text{Accuracy} = \frac{\text{True Positives (TP)} + \text{True Negatives (TN)}}{\text{Total Predictions}} $$

### 2. 정밀도 (Precision)
- **설명**: 양성으로 예측된 경우 중 실제로 양성인 비율
- **계산**: 
  $$ \text{Precision} = \frac{\text{True Positives (TP)}}{\text{True Positives (TP)} + \text{False Positives (FP)}} $$

### 3. 재현율 (Recall)
- **설명**: 실제 양성 중 모델이 양성으로 올바르게 예측한 비율
- **계산**: 
  $$ \text{Recall} = \frac{\text{True Positives (TP)}}{\text{True Positives (TP)} + \text{False Negatives (FN)}} $$


정밀도와 재현율 사이의 관계는 종종 상충관계(trade-off)로 묘사됩니다. 즉, 일반적으로 하나를 증가시키려 하면 다른 하나는 감소하는 경향이 있습니다. 예를 들어, 모델이 너무 엄격하여 오직 매우 확신하는 경우에만 '양성'으로 예측한다면 정밀도는 높아질 수 있지만, 일부 실제 양성 사례들을 놓칠 수 있어 재현율이 감소할 수 있습니다. 반대로, 모델이 너무 자주 '양성'으로 예측한다면 재현율은 증가하지만, 실제로는 양성이 아닌 경우들도 많이 포함되어 정밀도가 감소할 수 있습니다.

이러한 상충관계를 조절하고 평가하기 위해 F1 점수(F1 Score)라는 지표가 종종 사용됩니다. F1 점수는 정밀도와 재현율의 조화 평균을 나타내며, 이 두 지표를 동시에 고려하는 방법입니다.