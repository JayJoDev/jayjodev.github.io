---
title: 기계학습 기초 (자연어처리 BERT)
author: Jay Jo
date: 2023-11-25 00:00:00 +09:00
categories: [Artificial Intelligence]
tags: [AI]
image: /assets/img/posts/clustering.png
---

# BERT

[BERT 관련 설명](https://wikidocs.net/108730)

BERT (Bidirectional Encoder Representations from Transformers)는 자연어 처리 (NLP) 작업을 위한 사전 훈련 모델로, 텍스트 데이터를 다루는 클러스터링 작업에도 활용될 수 있습니다.

## 작업 개요

1. **데이터 수집 및 전처리**
   - 클러스터링을 위한 텍스트 데이터를 수집하고 전처리합니다.

2. **BERT 임베딩 추출**
   - BERT 모델을 사용하여 각 문서를 벡터로 임베딩합니다.
   - 문서를 토큰화하고 BERT 모델을 활용하여 임베딩을 생성합니다.

3. **클러스터링 알고리즘 적용**
   - 임베딩된 벡터를 클러스터링 알고리즘에 입력으로 제공합니다.
   - 일반적인 알고리즘으로는 K-means, DBSCAN, hierarchical clustering 등을 사용할 수 있습니다.

4. **클러스터링 결과 분석**
   - 클러스터링 알고리즘이 문서를 그룹화한 결과를 분석하고 시각화합니다.
   - 각 클러스터의 특징을 이해하고 필요한 경우 클러스터에 레이블을 할당합니다.

5. **평가 및 튜닝**
   - 클러스터링 결과를 평가하고 성능을 향상시키기 위해 알고리즘 매개변수를 조정하거나 다른 모델을 시도합니다.




